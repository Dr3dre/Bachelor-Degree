{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Dr3dre/Bachelor-Degree/blob/main/Anomaly_Detection_on_Wine_Grapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KS4CtJUO0YQ4",
    "outputId": "bde823fa-0af0-4c20-c889-0565064d54ec"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxxDNKpa0zkR"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLKQFb9K089i"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class CanopiesDataset(Dataset):\n",
    "    def __init__(self, image_names, transform):\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = np.array(Image.open(self.image_names[idx]).convert(\"RGB\"))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if \"good\" in self.image_names[idx]:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3xT3O4IsX2d"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "def get_image_paths(data_dir):\n",
    "    return [os.path.join(data_dir, image_name) for image_name in os.listdir(data_dir) if image_name.endswith(\".jpg\")]\n",
    "\n",
    "\n",
    "def get_images_by_scale(data_dir, scale):\n",
    "\n",
    "    good_dir = os.path.join(data_dir, \"good\")\n",
    "    good_dir_1 = os.path.join(good_dir, \"scale_1\")\n",
    "    good_dir_1_5 = os.path.join(good_dir, \"scale_1.5\")\n",
    "    good_dir_2 = os.path.join(good_dir, \"scale_2\")\n",
    "\n",
    "    good_images = []\n",
    "\n",
    "    if scale == 1 or scale == None:\n",
    "        good_images += get_image_paths(good_dir_1)\n",
    "\n",
    "    if scale == 1.5 or scale == None:\n",
    "        good_images += get_image_paths(good_dir_1_5)\n",
    "\n",
    "    if scale == 2 or scale == None:\n",
    "        good_images += get_image_paths(good_dir_2)\n",
    "\n",
    "\n",
    "    bad_dir = os.path.join(data_dir, \"bad\")\n",
    "    bad_dir_1 = os.path.join(bad_dir, \"scale_1\")\n",
    "    bad_dir_1_5 = os.path.join(bad_dir, \"scale_1.5\")\n",
    "    bad_dir_2 = os.path.join(bad_dir, \"scale_2\")\n",
    "\n",
    "    bad_images = []\n",
    "\n",
    "    if scale == 1 or scale is None:\n",
    "        bad_images += get_image_paths(bad_dir_1)\n",
    "\n",
    "    if scale == 1.5 or scale is None:\n",
    "        bad_images += get_image_paths(bad_dir_1_5)\n",
    "\n",
    "    if scale == 2 or scale is None:\n",
    "        bad_images += get_image_paths(bad_dir_2)\n",
    "\n",
    "    return good_images, bad_images\n",
    "\n",
    "\n",
    "def split_images_aux(images, train_percentage, val_percentage, train_limit, random_seed):\n",
    "\n",
    "    train_images = images[: int(len(images) * train_percentage)]\n",
    "    if train_limit is not None:\n",
    "        train_images = train_images[: train_limit]\n",
    "\n",
    "    val_images = images[\n",
    "        int(len(images) * train_percentage) :\n",
    "        int(len(images) * (train_percentage + val_percentage))\n",
    "    ]\n",
    "\n",
    "    test_images = images[\n",
    "        int(len(images) * (train_percentage + val_percentage)) :\n",
    "    ]\n",
    "\n",
    "    return train_images, val_images, test_images\n",
    "\n",
    "\n",
    "def split_images(good_images, bad_images, train_percentage, val_percentage, train_limit, random_seed):\n",
    "\n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    test_images = []\n",
    "\n",
    "    train_images_good, val_images_good, test_images_good = split_images_aux(good_images, train_percentage, val_percentage, train_limit, random_seed)\n",
    "    train_images_bad, val_images_bad, test_images_bad = split_images_aux(bad_images, train_percentage, val_percentage, train_limit, random_seed)\n",
    "\n",
    "    train_images += train_images_good\n",
    "    train_images += train_images_bad\n",
    "\n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(train_images)\n",
    "\n",
    "    val_images += val_images_good\n",
    "    val_images += val_images_bad\n",
    "\n",
    "    test_images += test_images_good\n",
    "    test_images += test_images_bad\n",
    "\n",
    "    print(f\"Good images for training: {len(train_images)}\")\n",
    "    print(f\"Good images for validation: {len(val_images)}\")\n",
    "    print(f\"Good images for testing: {len(test_images)}\")\n",
    "\n",
    "    print(f\"Bad images for training: {len(train_images_bad)}\")\n",
    "    print(f\"Bad images for validation: {len(val_images_bad)}\")\n",
    "    print(f\"Bad images for testing: {len(test_images_bad)}\")\n",
    "\n",
    "    return train_images, val_images, test_images\n",
    "\n",
    "def get_datasets(train_images, val_images, test_images, transform):\n",
    "\n",
    "    train_dataset = CanopiesDataset(\n",
    "        image_names = train_images,\n",
    "        transform = transform\n",
    "    )\n",
    "\n",
    "    val_dataset = CanopiesDataset(\n",
    "        image_names = val_images,\n",
    "        transform = transform\n",
    "    )\n",
    "\n",
    "    test_dataset = CanopiesDataset(\n",
    "        image_names = test_images,\n",
    "        transform = transform\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def get_loaders_(train_dataset, val_dataset, test_dataset, batch_size, num_workers):\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def get_loaders(data_dir,\n",
    "                batch_size,\n",
    "                train_percentage = 0.7,\n",
    "                val_percentage = 0.2,\n",
    "                train_limit = None,\n",
    "                transform = None,\n",
    "                num_workers = 2,\n",
    "                random_seed = 42,\n",
    "                scale = None):\n",
    "\n",
    "    good_images, bad_images = get_images_by_scale(data_dir, scale)\n",
    "\n",
    "    train_images, val_images, test_images = split_images(good_images, bad_images, train_percentage, val_percentage, train_limit, random_seed)\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = get_datasets(train_images, val_images, test_images, transform)\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_loaders_(train_dataset, val_dataset, test_dataset, batch_size, num_workers)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BG-pAGnBK0U",
    "outputId": "7b03bec5-d9bc-4e0c-d26c-475b05689947"
   },
   "outputs": [],
   "source": [
    "# print stats of dataset\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "DATA_DIR = \"/content/drive/MyDrive/first_dataset\"\n",
    "MODELS_DIR = \"/content/drive/MyDrive/canopies_models\"\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader, train_dataset, valid_dataset = get_loaders(\n",
    "        data_dir = DATA_DIR,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        train_percentage=0.7,\n",
    "        val_percentage=0.1,\n",
    "        transform=transform,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        train_limit=None,\n",
    "        random_seed=42,\n",
    "        scale = 1.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8-9yYxI96Jt"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nry5zRfosQkx",
    "outputId": "878a1b2a-3144-4c30-ccfe-38e6aa49f40f"
   },
   "outputs": [],
   "source": [
    "# calcolo media e standard deviation per normalizzare\n",
    "\n",
    "def batch_mean_and_sd(loader):\n",
    "\n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "\n",
    "    for images, _ in loader:\n",
    "        b, c, h, w = images.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(images ** 2,\n",
    "                                  dim=[0, 2, 3])\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (\n",
    "                      cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (\n",
    "                            cnt + nb_pixels)\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    mean, std = fst_moment, torch.sqrt(\n",
    "      snd_moment - fst_moment ** 2)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = batch_mean_and_sd(train_loader)\n",
    "print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aSfN8GKwy1bl",
    "outputId": "874e2a17-43a6-4e8a-f37e-8c637a2924be"
   },
   "outputs": [],
   "source": [
    "# Python code to visualize an image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform_NORMALIZED = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Normalize(mean = mean, std = std)\n",
    "    ]\n",
    ")\n",
    "\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "def display_image(images, limit=0):\n",
    "  images_np = images.numpy()\n",
    "  img_plt = images_np.transpose(0,2,3,1)\n",
    "\n",
    "  num_images = limit if limit > 0 else images.shape[0]\n",
    "\n",
    "  for i in range(num_images):\n",
    "    plt.imshow(img_plt[i])\n",
    "    plt.show()\n",
    "\n",
    "display_image(images, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zkjYU-zM1YFA",
    "outputId": "b7c34b1a-21eb-4e47-90e7-20849cc52a32"
   },
   "outputs": [],
   "source": [
    "image_norm = transform_NORMALIZED(images)\n",
    "\n",
    "display_image(image_norm, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJBPSQlb-Cin"
   },
   "source": [
    "#### Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBWEeqbIAO8m",
    "outputId": "ecf68c19-8b91-4843-9e18-8b50cecfc4f3"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "data_dir = \"/content/drive/MyDrive/first_dataset\"\n",
    "scale = 1.5\n",
    "train_percentage = 0.7\n",
    "val_percentage = 0.2\n",
    "train_limit = None\n",
    "random_seed = 42\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "# concatena al train_dataset originale i 3 bad_dataset ruotati\n",
    "\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "# trasformazioni per la rotazione delle immagini\n",
    "rotate_90 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation([89.9, 90.1]),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "rotate_180 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation([179.9, 180.1]),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "rotate_270 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation([269.9, 270.1]),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "offset = 0.1\n",
    "\n",
    "good_images, bad_images = get_images_by_scale(data_dir, scale)\n",
    "\n",
    "train_images_good, val_images_good, test_images_good = split_images_aux(good_images, train_percentage, 0.1, train_limit, random_seed)\n",
    "train_images_bad, val_images_bad, test_images_bad = split_images_aux(bad_images, train_percentage - offset, val_percentage + offset, train_limit, random_seed)\n",
    "\n",
    "train_dataset_good = CanopiesDataset(train_images_good, normalize)\n",
    "train_dataset_bad = CanopiesDataset(train_images_bad, normalize)\n",
    "bad90_dataset = CanopiesDataset(train_images_bad, rotate_90)\n",
    "bad180_dataset = CanopiesDataset(train_images_bad, rotate_180)\n",
    "bad270_dataset = CanopiesDataset(train_images_bad, rotate_270)\n",
    "\n",
    "train_dataset = ConcatDataset([train_dataset_good, train_dataset_bad, bad90_dataset, bad180_dataset, bad270_dataset])\n",
    "\n",
    "val_images = []\n",
    "test_images = []\n",
    "\n",
    "val_images += val_images_good\n",
    "val_images += val_images_bad\n",
    "\n",
    "test_images += test_images_good\n",
    "test_images += test_images_bad\n",
    "\n",
    "_, val_dataset, test_dataset = get_datasets(train_images_good, val_images, test_images, normalize)\n",
    "\n",
    "train_loader, val_loader, test_loader = get_loaders_(train_dataset, val_dataset, test_dataset, batch_size, num_workers)\n",
    "\n",
    "print(len(val_images_good), len(val_images_bad))\n",
    "print(len(test_images_good), len(test_images_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcnrkhnUeEuN",
    "outputId": "0c1b585c-09bf-405d-c38c-5a40462e48d5"
   },
   "outputs": [],
   "source": [
    "len_bad = 0\n",
    "for i in range(1, 5):\n",
    "    len_bad += train_dataset.datasets[i].__len__()\n",
    "\n",
    "print(\"Good images for training: \", train_dataset.datasets[0].__len__())\n",
    "print(\"Bad images for training: \", len_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7Yt1crRoXKs",
    "outputId": "380011cd-7e89-4963-a1e9-a98e6bad8418"
   },
   "outputs": [],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjrd4eeWew-9"
   },
   "source": [
    "### Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCeB3IspDGpC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # Primo Layer convoluzionale\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Secondo Layer convoluzionale\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flat = nn.Flatten(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(50 * 109 * 109, 500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrDWnbN31xJT"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Av8XQW_espTw"
   },
   "source": [
    "#### funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8WU4qIr1zHG"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(\n",
    "    loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    verbose = False,\n",
    "    show_preds = False\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    acc_sum = 0\n",
    "    loss_sum = 0\n",
    "\n",
    "    true_unharmed = 0\n",
    "    true_damaged = 0\n",
    "    false_unharmed = 0\n",
    "    false_damaged = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loader):\n",
    "        data = data.to(device=device)\n",
    "        targets_hot = F.one_hot(targets, 2).float()\n",
    "        targets_hot = targets_hot.to(device=device)\n",
    "\n",
    "        predictions = model(data)\n",
    "        loss = criterion(predictions, targets_hot)\n",
    "\n",
    "        if(show_preds):\n",
    "            print(predictions)\n",
    "            print(targets_hot)\n",
    "\n",
    "        acc_cur = accuracy_score(predictions.argmax(dim=1).cpu(), targets.cpu())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(loader)}, Train Loss: {loss.item()}, Accuracy del batch: {acc_cur}\")\n",
    "\n",
    "        acc_sum += acc_cur\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        preds = predictions.argmax(dim=1)\n",
    "        for i in range(len(preds)):\n",
    "            if targets[i] == 0 and preds[i] == 0:\n",
    "                true_unharmed += 1\n",
    "            if targets[i] == 0 and preds[i] == 1:\n",
    "                false_damaged += 1\n",
    "            if targets[i] == 1 and preds[i] == 0:\n",
    "                false_unharmed += 1\n",
    "            if targets[i] == 1 and preds[i] == 1:\n",
    "                true_damaged += 1\n",
    "\n",
    "    cm = [[true_unharmed, false_damaged],\n",
    "          [false_unharmed, true_damaged]]\n",
    "\n",
    "\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    if (true_damaged + false_damaged) != 0:\n",
    "        precision = true_damaged / (true_damaged + false_damaged)\n",
    "    if (true_damaged + false_unharmed) != 0:\n",
    "        recall = true_damaged / (true_damaged + false_unharmed)\n",
    "\n",
    "    print(f\"Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "    print(cm[0][0], cm[0][1])\n",
    "    print(cm[1][0], cm[1][1])\n",
    "\n",
    "    acc_epoch = acc_sum / len(loader)\n",
    "    loss_avg = loss_sum / len(loader)\n",
    "\n",
    "    if verbose: print(f\"Epoch accuracy: {acc_epoch}\")\n",
    "\n",
    "    return acc_epoch, loss_avg, cm, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-Zt8hRzs5v6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def test(\n",
    "    loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device\n",
    "):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    acc_sum = 0\n",
    "\n",
    "    true_unharmed = 0\n",
    "    true_damaged = 0\n",
    "    false_unharmed = 0\n",
    "    false_damaged = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            data = data.to(device=device)\n",
    "            targets_hot = F.one_hot(targets, 2).float()\n",
    "            targets_hot = targets_hot.to(device=device)\n",
    "\n",
    "            predictions = model(data)\n",
    "\n",
    "            loss = criterion(predictions, targets_hot)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = predictions.argmax(dim=1)\n",
    "            acc_cur = accuracy_score(predictions.argmax(dim=1).cpu(), targets.cpu())\n",
    "            acc_sum += acc_cur\n",
    "\n",
    "            # confusion_matrix:\n",
    "            preds = preds.cpu()\n",
    "            targets = targets.cpu()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                if targets[i] == 0 and preds[i] == 0:\n",
    "                    true_unharmed += 1\n",
    "                if targets[i] == 0 and preds[i] == 1:\n",
    "                    false_damaged += 1\n",
    "                if targets[i] == 1 and preds[i] == 0:\n",
    "                    false_unharmed += 1\n",
    "                if targets[i] == 1 and preds[i] == 1:\n",
    "                    true_damaged += 1\n",
    "\n",
    "    acc = acc_sum / len(loader)\n",
    "    loss = total_loss / len(loader)\n",
    "\n",
    "    cm = [[true_unharmed, false_damaged],\n",
    "          [false_unharmed, true_damaged]]\n",
    "\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    if (true_damaged + false_damaged) != 0:\n",
    "        precision = true_damaged / (true_damaged + false_damaged)\n",
    "    if (true_damaged + false_unharmed) != 0:\n",
    "        recall = true_damaged / (true_damaged + false_unharmed)\n",
    "\n",
    "    print(f\"Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "    print(cm[0][0], cm[0][1])\n",
    "    print(cm[1][0], cm[1][1])\n",
    "\n",
    "    return acc, loss, cm, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_0_8-OA431L"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def train_model(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs,\n",
    "    model_path,\n",
    "    device,\n",
    "    save_model = False\n",
    "):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoca n°{epoch}\\n\")\n",
    "        train_acc, train_loss, _, train_precision, train_recall = train(train_loader, model, optimizer, criterion, device, verbose=False)\n",
    "        val_acc, val_loss, _, val_precision, val_recall = test(val_loader, model, criterion, device)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            if save_model:\n",
    "                checkpoint = {\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"val_loss\": val_loss\n",
    "                }\n",
    "                torch.save(checkpoint, model_path)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        train_precisions.append(train_precision)\n",
    "        val_precisions.append(val_precision)\n",
    "\n",
    "        train_recalls.append(train_recall)\n",
    "        val_recalls.append(val_recall)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Grafico 1 - Loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training loss\", color=\"blue\")\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation loss\", color=\"orange\")\n",
    "    plt.title(f\"Optimizer: {optimizer}\\nLoss durante addestramento\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # Grafico 2 - Accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, len(train_accs) + 1), train_accs, label=\"Training accuracy\", color=\"green\")\n",
    "    plt.plot(range(1, len(val_accs) + 1), val_accs, label=\"Validation accuracy\", color=\"red\")\n",
    "    plt.title(\"Accuratezza durante l'addestramento\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # Grafico 3 - Precision e Recall\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(1, len(train_precisions) + 1), train_precisions, label=\"Training precision\", color=\"purple\")\n",
    "    plt.plot(range(1, len(val_precisions) + 1), val_precisions, label=\"Validation precision\", color=\"pink\")\n",
    "    plt.plot(range(1, len(train_recalls) + 1), train_recalls, label=\"Training recall\", color=\"brown\")\n",
    "    plt.plot(range(1, len(val_recalls) + 1), val_recalls, label=\"Validation recall\", color=\"gray\")\n",
    "    plt.title(\"Precision e Recall durante l'addestramento\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel('Epoche')\n",
    "    plt.ylabel('Precision/Recall')\n",
    "\n",
    "    plt.tight_layout()  # Per evitare sovrapposizioni\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcE6-X-Ig4aQ"
   },
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k88EN2WZRLee"
   },
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1ZCs2Th24qd"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "MODELS_DIR = \"/content/drive/MyDrive/canopies_models\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "SAVE_MODELS = False\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkB4mc-8g4Bh"
   },
   "outputs": [],
   "source": [
    "# SGD\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "lrs = [0.1, 0.01, 0.001]              # Tasso di apprendimento\n",
    "momentums = [0, 0.9, 0.95, 0.99]      # Momentum\n",
    "weight_decays = [0.0, 0.001, 0.01]    # Decadimento del peso (L2 regularization)\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "for lr in lrs:\n",
    "    for momentum in momentums:\n",
    "        for weight_decay in weight_decays:\n",
    "\n",
    "            print(f\"lr: {lr}, momentum: {momentum}, wd: {weight_decay}\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            model = LeNet(num_classes=2).to(DEVICE)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "            if SAVE_MODELS:\n",
    "\n",
    "                model_id = f\"LeNet_sc{None}_lr{lr}_mom{momentum}_wd{weight_decay}_limit{TRAIN_LIMIT}.pth\"\n",
    "\n",
    "                os.makedirs(os.path.join(MODELS_DIR, f\"seed_{RANDOM_SEED}\"), exist_ok=True)\n",
    "                model_path = os.path.join(MODELS_DIR, f\"seed_{RANDOM_SEED}\", model_id)\n",
    "\n",
    "            train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "            train_losses_.append(train_losses[-1])\n",
    "            val_losses_.append(val_losses[-1])\n",
    "            train_accs_.append(train_accs[-1])\n",
    "            val_accs_.append(val_accs[-1])\n",
    "\n",
    "            if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "              best_params[\"lr\"] = lr\n",
    "              best_params[\"momentum\"] = momentum\n",
    "              best_params[\"weight_decay\"] = weight_decay\n",
    "              best_params[\"scale\"] = None   # scale\n",
    "              best_params[\"val_loss\"] = val_losses[-1]\n",
    "              best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kljiWZfRPNLM",
    "outputId": "088845f0-fd75-4dff-e6a2-8e72eb6b6c6c"
   },
   "outputs": [],
   "source": [
    "TRAIN_LIMIT = 800\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "SAVE_MODELS = False\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "params15 = [\n",
    "    [0.01, 0, 0.001],\n",
    "    [0.01, 0, 0.01],\n",
    "    [0.001, 0, 0.01],\n",
    "    [0.001, 0.9, 0.001],\n",
    "    [0.001, 0.95, 0.0],\n",
    "    [0.001, 0.99, 0.01]\n",
    "]\n",
    "\n",
    "params = [\n",
    "    [0.1, 0, 0.0],\n",
    "    [0.01, 0, 0.0],\n",
    "    [0.01, 0, 0.01],\n",
    "    [0.001, 0, 0.0],\n",
    "    [0.001, 0, 0.001],\n",
    "    [0.001, 0, 0.01],\n",
    "    [0.001, 0.9, 0.001],\n",
    "    [0.001, 0.95, 0.0],\n",
    "    [0.001, 0.95, 0.001],\n",
    "    [0.001, 0.99, 0.0]\n",
    "]\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "params = params15\n",
    "\n",
    "\n",
    "for i in range(len(params)):\n",
    "\n",
    "    lr = params[i][0]\n",
    "    momentum = params[i][1]\n",
    "    weight_decay = params[i][2]\n",
    "\n",
    "    print(f\"lr: {lr}, momentum: {momentum}, wd: {weight_decay}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LeNet(num_classes=2).to(DEVICE)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "    train_losses_.append(train_losses[-1])\n",
    "    val_losses_.append(val_losses[-1])\n",
    "    train_accs_.append(train_accs[-1])\n",
    "    val_accs_.append(val_accs[-1])\n",
    "\n",
    "    if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "        best_params[\"lr\"] = lr\n",
    "        best_params[\"momentum\"] = momentum\n",
    "        best_params[\"weight_decay\"] = weight_decay\n",
    "        best_params[\"scale\"] = None   # scale\n",
    "        best_params[\"val_loss\"] = val_losses[-1]\n",
    "        best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Uhu1rmh0pzkX",
    "outputId": "b62491a1-ad26-426c-bfc5-61f57dc56644"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "\n",
    "params = [\n",
    "    [0.001, 0, 0.0],\n",
    "    [0.001, 0, 0.001],\n",
    "    [0.001, 0, 0.01],\n",
    "    [0.001, 0.9, 0.001],\n",
    "    [0.001, 0.95, 0.0],\n",
    "    [0.001, 0.95, 0.001],\n",
    "    [0.001, 0.99, 0.0]\n",
    "]\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "\n",
    "for i in range(len(params)):\n",
    "\n",
    "    lr = params[i][0]\n",
    "    momentum = params[i][1]\n",
    "    weight_decay = params[i][2]\n",
    "\n",
    "    print(f\"lr: {lr}, momentum: {momentum}, wd: {weight_decay}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LeNet(num_classes=2).to(DEVICE)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "    train_losses_.append(train_losses[-1])\n",
    "    val_losses_.append(val_losses[-1])\n",
    "    train_accs_.append(train_accs[-1])\n",
    "    val_accs_.append(val_accs[-1])\n",
    "\n",
    "    if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "        best_params[\"lr\"] = lr\n",
    "        best_params[\"momentum\"] = momentum\n",
    "        best_params[\"weight_decay\"] = weight_decay\n",
    "        best_params[\"scale\"] = None   # scale\n",
    "        best_params[\"val_loss\"] = val_losses[-1]\n",
    "        best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8ITauJAF0R0w",
    "outputId": "a53e8184-2cb2-4014-da50-e20183403174"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "\n",
    "params15 = [\n",
    "    [0.001, 0, 0.001],\n",
    "    [0.001, 0.9, 0.001],\n",
    "]\n",
    "\n",
    "params = [\n",
    "    [0.001, 0, 0.0],\n",
    "    [0.001, 0, 0.001],\n",
    "    [0.001, 0, 0.01],\n",
    "    [0.001, 0.95, 0.001],\n",
    "]\n",
    "\n",
    "params = params15\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "\n",
    "for i in range(len(params)):\n",
    "\n",
    "    lr = params[i][0]\n",
    "    momentum = params[i][1]\n",
    "    weight_decay = params[i][2]\n",
    "\n",
    "    print(f\"lr: {lr}, momentum: {momentum}, wd: {weight_decay}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LeNet(num_classes=2).to(DEVICE)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "    train_losses_.append(train_losses[-1])\n",
    "    val_losses_.append(val_losses[-1])\n",
    "    train_accs_.append(train_accs[-1])\n",
    "    val_accs_.append(val_accs[-1])\n",
    "\n",
    "    if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "        best_params[\"lr\"] = lr\n",
    "        best_params[\"momentum\"] = momentum\n",
    "        best_params[\"weight_decay\"] = weight_decay\n",
    "        best_params[\"scale\"] = None   # scale\n",
    "        best_params[\"val_loss\"] = val_losses[-1]\n",
    "        best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FqdARU14HpJF",
    "outputId": "c00e1036-74d8-40ac-b7a4-f2f91ef07ae9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "params = [\n",
    "    [0.001, 0, 0.001],\n",
    "    [0.001, 0, 0.01],\n",
    "]\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "\n",
    "for i in range(len(params)):\n",
    "\n",
    "    lr = params[i][0]\n",
    "    momentum = params[i][1]\n",
    "    weight_decay = params[i][2]\n",
    "\n",
    "    print(f\"lr: {lr}, momentum: {momentum}, wd: {weight_decay}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LeNet(num_classes=2).to(DEVICE)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "    train_losses_.append(train_losses[-1])\n",
    "    val_losses_.append(val_losses[-1])\n",
    "    train_accs_.append(train_accs[-1])\n",
    "    val_accs_.append(val_accs[-1])\n",
    "\n",
    "    if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "        best_params[\"lr\"] = lr\n",
    "        best_params[\"momentum\"] = momentum\n",
    "        best_params[\"weight_decay\"] = weight_decay\n",
    "        best_params[\"scale\"] = None   # scale\n",
    "        best_params[\"val_loss\"] = val_losses[-1]\n",
    "        best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWA7nazAREH-"
   },
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tRF3wIq72rrO",
    "outputId": "5aaa0757-90fe-4466-a878-2a18f3c50191"
   },
   "outputs": [],
   "source": [
    "# ADAM\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "DATA_DIR = \"/content/drive/MyDrive/first_dataset\"\n",
    "BATCH_SIZE = 40\n",
    "TRAIN_LIMIT = 800\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "MODELS_DIR = \"/content/drive/MyDrive/canopies_models\"\n",
    "\n",
    "SAVE_MODELS = False\n",
    "\n",
    "pos_weight = torch.tensor([2, 1]).to(device=DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() #(pos_weight=pos_weight)\n",
    "\n",
    "lrs = [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "weight_decays = [0] # [0, 1e-4, 1e-3, 1e-2]\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    \"lr\" : 0,\n",
    "    \"momentum\" : 0,\n",
    "    \"weight_decay\" : 0,\n",
    "    \"scale\" : 0,\n",
    "    \"val_loss\" : 10,\n",
    "    \"val_acc\" : 0\n",
    "}\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "\n",
    "for lr, weight_decay in list(product(lrs, weight_decays)):\n",
    "\n",
    "    print(f\"lr: {lr}, wd: {weight_decay}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = LeNet(num_classes=2).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                NUM_EPOCHS,\n",
    "                MODELS_DIR,\n",
    "                DEVICE,\n",
    "                SAVE_MODELS\n",
    "            )\n",
    "\n",
    "\n",
    "    train_losses_.append(train_losses[-1])\n",
    "    val_losses_.append(val_losses[-1])\n",
    "    train_accs_.append(train_accs[-1])\n",
    "    val_accs_.append(val_accs[-1])\n",
    "\n",
    "    if (val_losses[-1] <= best_params[\"val_loss\"] and val_accs[-1] >= best_params[\"val_acc\"]):\n",
    "        best_params[\"lr\"] = lr\n",
    "        best_params[\"weight_decay\"] = weight_decay\n",
    "        best_params[\"scale\"] = None   # scale\n",
    "        best_params[\"val_loss\"] = val_losses[-1]\n",
    "        best_params[\"val_acc\"] = val_accs[-1]\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0V4MBfB6KYT"
   },
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bbKl4s9tEYdP",
    "outputId": "1e54c555-2d65-4b3e-b728-3c301f300463"
   },
   "outputs": [],
   "source": [
    "# scala 1.5\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "SAVE_MODELS = False\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0\n",
    "weight_decay =  0.001\n",
    "\n",
    "train_losses_ = []\n",
    "val_losses_ = []\n",
    "train_accs_ = []\n",
    "val_accs_ = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = LeNet(num_classes=2).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            NUM_EPOCHS,\n",
    "            MODELS_DIR,\n",
    "            DEVICE,\n",
    "            SAVE_MODELS\n",
    "        )\n",
    "\n",
    "train_losses_.append(train_losses[-1])\n",
    "val_losses_.append(val_losses[-1])\n",
    "train_accs_.append(train_accs[-1])\n",
    "val_accs_.append(val_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96yttJGgCu55"
   },
   "outputs": [],
   "source": [
    "save_path = '/content/drive/MyDrive/canopies_models/main/modello.pth'\n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EZnnEDkGnSI"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ql9Kf7AGpR0"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loaders, criterion, device):\n",
    "    model.eval()\n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    acc_train, loss_train, cm_train, precision_train, recall_train = test(data_loaders[0], model, criterion, device)\n",
    "    acc_val, loss_val, cm_val, precision_val, recall_val = test(data_loaders[1], model, criterion, device)\n",
    "    acc_test, loss_test, cm_test, precision_test, recall_test = test(data_loaders[2], model, criterion, device)\n",
    "\n",
    "    print(f\"Accuracy on Train: {acc_train*100:.2f}%, Loss: {loss_train:.2f}\")\n",
    "    print(f\"Precision on Train: {precision_train:.2f}, Recall on Train: {recall_train:.2f}\")\n",
    "\n",
    "    print(f\"Accuracy on Validation: {acc_val*100:.2f}%, Loss: {loss_val:.2f}\")\n",
    "    print(f\"Precision on Validation: {precision_val:.2f}, Recall on Validation: {recall_val:.2f}\")\n",
    "\n",
    "    print(f\"Accuracy on Test: {acc_test*100:.2f}%, Loss: {loss_test:.2f}\")\n",
    "    print(f\"Precision on Test: {precision_test:.2f}, Recall on Test: {recall_test:.2f}\")\n",
    "\n",
    "    return cm_train, cm_val, cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3i_lvkZ3T_EL"
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# testa tutti i modelli salvati\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "IMAGE_HEIGHT = IMAGE_WIDTH = 300\n",
    "\n",
    "DATA_DIR = \"/content/drive/MyDrive/first_dataset\"\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "TRAIN_LIMIT = 500\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH), antialias=True),\n",
    "    ]\n",
    ")\n",
    "_, _, _, train_dataset = get_loaders(\n",
    "    data_dir = DATA_DIR,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    train_percentage=0.7,\n",
    "    val_percentage=0.1,\n",
    "    transform=transform,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    train_limit=TRAIN_LIMIT,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    scale = None\n",
    ")\n",
    "\n",
    "mean, std = get_mean_std(train_loader)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH), antialias=True),\n",
    "        torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader, _ = get_loaders(\n",
    "    data_dir = DATA_DIR,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    train_percentage=0.7,\n",
    "    val_percentage=0.1,\n",
    "    transform=transform,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    train_limit=TRAIN_LIMIT,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    scale = None\n",
    ")\n",
    "\n",
    "models_folder = \"/content/drive/MyDrive/canopies_models/seed_42\"\n",
    "model_files = os.listdir(models_folder)\n",
    "\n",
    "# Itera attraverso i file dei modelli\n",
    "for model_file in model_files:\n",
    "    if model_file.endswith(\".pth\"):\n",
    "        model_path = os.path.join(models_folder, model_file)\n",
    "\n",
    "        model = LeNet().to(DEVICE)  # Sostituisci con la definizione del tuo modello\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE)['model_state_dict'])\n",
    "\n",
    "        # Esegui eval_model sul modello\n",
    "        print(\"\\n\", model_file)\n",
    "        cm_train, cm_val, cm_test = eval_model(model, [train_loader, val_loader, test_loader], criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5fk8LTJU88RZ",
    "outputId": "6c1a3ebf-14f8-47e7-c4d0-93743225a939"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/std[0], 1/std[1], 1/std[2] ]),\n",
    "                                transforms.Normalize(mean = [ -mean[0], -mean[1], -mean[2] ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "# inv_tensor = invTrans(inp_tensor)\n",
    "\n",
    "# visualizzazione delle immagini con etichetta e predizione\n",
    "def visualize_predictions(loader, model, device, limit=150):\n",
    "    model.eval()\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.numpy()  # Converti le etichette in un array NumPy\n",
    "            predictions = model(data)\n",
    "            predictions = predictions.argmax(dim=1).cpu().numpy()  # Converti le predizioni in un array NumPy\n",
    "            for i in range(len(data)):\n",
    "                tensor = data[i]\n",
    "                tensor_unnorm = invTrans(tensor)\n",
    "                image = tensor_unnorm.permute(1, 2, 0).cpu().numpy()  # Trasforma il tensore in un array NumPy per la visualizzazione\n",
    "                plt.imshow(image)\n",
    "                true_label = targets[i]\n",
    "                predicted_label = predictions[i]\n",
    "                plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "                plt.show()\n",
    "\n",
    "                count += 1\n",
    "                if count >= limit:\n",
    "                    return\n",
    "\n",
    "visualize_predictions(test_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "_OPtHcVQOA3j",
    "outputId": "b4e4e111-4aca-42dd-83d8-ea854d27bc71"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_train, cm_val, cm_test = eval_model(model, [train_loader, val_loader, test_loader], criterion, DEVICE)\n",
    "\n",
    "sns.heatmap(cm_test, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "L-dv4fpRMFG_",
    "outputId": "db4e268e-4239-44e9-c6fa-27f4e05889df"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm_train, cm_val, cm_test = eval_model(model, [train_loader, val_loader, test_loader], criterion, DEVICE)\n",
    "\n",
    "class_names = [\"Unharmed\", \"Damaged\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Train\n",
    "sns.heatmap(cm_train, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Train')\n",
    "\n",
    "# Validation\n",
    "sns.heatmap(cm_val, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - Validation')\n",
    "\n",
    "# Test\n",
    "sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=axes[2])\n",
    "axes[2].set_title('Confusion Matrix - Test')\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9rsY95FAjnas",
    "outputId": "dd1b7688-c908-46dc-e692-464d5ed96ee2"
   },
   "outputs": [],
   "source": [
    "visualize_predictions(val_loader, model, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TxxDNKpa0zkR"
   ],
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
